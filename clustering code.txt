Arm: Practical of k means dustering.
Theory:
some of the key features of k-means are as follow: - k-means an exploratory data analysis.

technique.

Implements nonhierarchical method of grouping objects together

k-means determines the centroid

using

Euclidean method for distance calculation After calculating minimum distaces group of objects are created by considering the miniumum distance.

k-means clustering is a type of usupervised which is used when labeled data you hane

1 "The goal of this algorithm is to find. groups in the data, with the number of groups. represented by variable k The algorithm works iteratively to assign each data point to one * on the features that are provided. groups based
Labels for the training data Rather than defining groups belone looking at the data clustering allows you to find and analyze the groups of can be determined.

Each controid of cluster is a collection of feature values which define the resulting groups Examining the Controld feature weights can be used to qualitatively interpret what kind of each cluster reprients.

1 This introduction to the k-means clustering algorithm Covers:

Common, business cases where k-means is used. • The steps involved in inourning the

algorithm A python example using delivery fleet data.



"k-means clustering "
data("iris")
names(iris)
new_data<-subset(iris,select = c(-Species))
new_data
cl <- kmeans(new_data,3)
cl
data <- new_data
wss <- sapply(1:15, function(k){kmeans(data, k )$tot.withinss})
wss
plot(1:15, wss, type="b", pch=19, frame=FALSE, xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
install.packages("cluster")
library(cluster)
clusplot(new_data, cl$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
cl$cluster
cl$centers
"agglomerative clustering"
clusters <- hclust(dist(iris[, 3:4]))
plot(clusters)
clusterCut <- cutree(clusters, 3)
table(clusterCut, iris$Species)
install.packages("ggplot2")
library("ggplot2")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) +
geom_point(alpha = 0.4, size = 3.5) + geom_point(col = clusterCut) +
scale_color_manual(values = c('black', 'red', 'green'))
clusters <- hclust(dist(iris[, 3:4]), method='average')
clusterCut1 <- cutree(clusters, 3)
table(clusterCut1, iris$Species)
plot(clusters)
ggplot(iris, aes(Petal.Length, Petal.Width, color=Species)) +
geom_point(alpha = 0.4, size = 3.5) + geom_point(col=clusterCut1) +
scale_color_manual(values = c('black', 'red', 'green'))
